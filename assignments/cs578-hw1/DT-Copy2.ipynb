{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = {\n",
    "    'A1': ['b','a'],\n",
    "    'A2': 'continuous',\n",
    "    'A3': 'continuous',\n",
    "    'A4': ['u','y','l','t'],\n",
    "    'A5': ['g','p','gg'],\n",
    "    'A6': ['c','d','cc','i','j','k','m','r','q','w','x','e','aa','ff'],\n",
    "    'A7': ['v','h','bb','j','n','z','dd','ff','o'],\n",
    "    'A8': 'continuous',\n",
    "    'A9': ['t','f'],\n",
    "    'A10': ['t','f'],\n",
    "    'A11': 'continuous',\n",
    "    'A12': ['t','f'],\n",
    "    'A13': ['g','p','s'],\n",
    "    'A14': 'continuous',\n",
    "    'A15': 'continuous',\n",
    "    'A16': ['+','-'],\n",
    "}\n",
    "attributes_copy = attributes.copy()\n",
    "attributes_copy.pop('A16')\n",
    "len(attributes_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element ? exists in Dataframe\n"
     ]
    }
   ],
   "source": [
    "train_df= pd.read_csv(\"train.txt\",sep = '\\t', header = None, names = attributes.keys())\n",
    "train_df\n",
    "if '?' in train_df.values:\n",
    "    print('Element ? exists in Dataframe')\n",
    "else:\n",
    "    print('Element ? does not exists in Dataframe')\n",
    "# type(df)\n",
    "# train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_missing_values(df):\n",
    "#     for key in df.keys():\n",
    "#         df[key] = df[key].replace('?',df[key].mode()[0])\n",
    "#     return df\n",
    "        \n",
    "# fill_missing_values(train_df)\n",
    "# if '?' in train_df.values:\n",
    "#     print('Element ? exists in Dataframe')\n",
    "# else:\n",
    "#     print('Element ? does not exists in Dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element ? does not exists in Dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garga\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_values(df):\n",
    "    # Filling in Missing Values\n",
    "    for i in range(1, 16):\n",
    "        attribute = 'A'+str(i)\n",
    "        if type(attributes.get(attribute))!=list:\n",
    "            mean_value = pd.to_numeric(df[df[attribute] != '?'][attribute]).mean()\n",
    "            df[attribute] = pd.to_numeric(df[attribute].replace('?', mean_value))\n",
    "        else:\n",
    "            value_counts = df[attribute].value_counts()\n",
    "            mode_value = None\n",
    "            for index, value in value_counts.items():\n",
    "                if index != '?':\n",
    "                    mode_value = index\n",
    "                    break\n",
    "            if mode_value == None:\n",
    "                print('Unable to find values other than \\'?\\'')\n",
    "            df[attribute] = df[attribute].replace('?', mode_value)\n",
    "fill_missing_values(train_df)\n",
    "if '?' in train_df.values:\n",
    "    print('Element ? exists in Dataframe')\n",
    "else:\n",
    "    print('Element ? does not exists in Dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 16) (98, 16)\n"
     ]
    }
   ],
   "source": [
    "def train_validation_split(df):\n",
    "    df = df.sample(frac=1)\n",
    "    size = int(0.8 * len(df))\n",
    "    train_data = df[:size]\n",
    "    val_data = df[size:]\n",
    "    return train_data, val_data\n",
    "train_set, val_set = train_validation_split(train_df)\n",
    "print(train_set.shape, val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical',\n",
       " 'continuous',\n",
       " 'continuous',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'continuous',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'continuous',\n",
       " 'categorical',\n",
       " 'categorical',\n",
       " 'continuous',\n",
       " 'continuous']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 14\n",
    "    for feature in df.columns:\n",
    "#         print(feature)\n",
    "        if feature != \"A16\":\n",
    "            unique_values = df[feature].unique()\n",
    "#             example_value = unique_values[0]\n",
    "\n",
    "            if (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "#                 print('c')\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "#                 print('conti')\n",
    "    \n",
    "    return feature_types\n",
    "feature_types = determine_type_of_feature(train_df)\n",
    "feature_types\n",
    "# feature_types[int(find_winner(train_df)[0][1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      30.83\n",
       "1      24.50\n",
       "2      20.17\n",
       "3      32.08\n",
       "4      45.83\n",
       "       ...  \n",
       "485    21.08\n",
       "486    22.67\n",
       "487    25.25\n",
       "488    17.92\n",
       "489    35.00\n",
       "Name: A2, Length: 490, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_dict = {}\n",
    "train_df['A2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def continuous_to_categorical_data(data):\n",
    "#     copy_data= data.copy()\n",
    "#     for key in copy_data.keys()[:-1]:\n",
    "#         if(type(attributes.get(key))!=list):\n",
    "# #             print(key)\n",
    "#             column_data = copy_data[key].astype(np.float)\n",
    "# #             print(\"CD\", column_data)\n",
    "# #             print(type(copy_data[key]))\n",
    "#             target_values = copy_data[\"A16\"]\n",
    "#             mydict = list(zip(column_data, target_values))\n",
    "#             sorted_dic=sorted(mydict)\n",
    "# #             print(sorted_dic)\n",
    "#             new_column_data=pd.DataFrame(sorted_dic,columns=[0,\"A16\"])\n",
    "# #             print(\"NCD\", new_column_data[0][1])\n",
    "#             my_column_changes = new_column_data[\"A16\"].shift() != new_column_data[\"A16\"]\n",
    "# #             print(\"MCC\", my_column_changes)\n",
    "#             my_column_changes.iloc[0] = False\n",
    "#             split_index= list(my_column_changes).index(True)\n",
    "# #             print(\"Index\", split_index)\n",
    "#             #print(\"Index for splitting the attribute is: \", split_index)\n",
    "#             #print(new_column_data[0].tolist())\n",
    "#             #print(\"-----------\")\n",
    "#             #print(new_column_data[\"Approved\"].tolist())\n",
    "#             #max_info_gain,split_value=max_IG_split(new_column_data,new_column_data[0])\n",
    "#             #print(new_column_data[0][split_index-1])\n",
    "#             #print(new_column_data[\"Approved\"][split_index-1])\n",
    "#             #print(new_column_data[0][split_index])\n",
    "#             #print(new_column_data[\"Approved\"][split_index])\n",
    "#             split_value = (float)(new_column_data[0][split_index] +new_column_data[0][split_index-1])/2.0\n",
    "#             print(\"Value\", split_value)\n",
    "#             threshold_dict[key]=split_value\n",
    "#             copy_data.loc[(column_data >= split_value), key] = 'Val >='+str(split_value)\n",
    "#             copy_data.loc[(column_data < split_value), key] = 'Val <'+str(split_value)\n",
    "# #             copy_data[key]=np.where(new_column_data >= split_value,'Val >='+str(split_value), 'Val <'+str(split_value))\n",
    "           \n",
    "#     return copy_data\n",
    "# transformed_data = continuous_to_categorical_data(train_df)\n",
    "# transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "\n",
    "def entropy_continuous(df,data_portion):\n",
    "    data_portion_count = len(data_portion)\n",
    "#     print(\"In entropy continuous:\" , data_portion_count)\n",
    "    output = {}\n",
    "    entropy = 0\n",
    "    for x,y in data_portion:\n",
    "        if y in output:\n",
    "            output[y].append((x,y))\n",
    "        else:\n",
    "            output[y] = [(x,y)]\n",
    "#     print(\"In entropy continuous:\", output)\n",
    "#     print(\"In entropy continuous:\", len(output.get('+')))\n",
    "    if ('+' in output.keys()):\n",
    "        pos_labels_count = len(output.get('+'))\n",
    "    else:\n",
    "        pos_labels_count = 0\n",
    "    neg_labels_count = data_portion_count - pos_labels_count\n",
    "    pos_fraction = pos_labels_count/(data_portion_count+eps)\n",
    "    pos_entropy = -pos_fraction*log(pos_fraction+eps)\n",
    "    neg_fraction = neg_labels_count/(data_portion_count+eps)\n",
    "    neg_entropy = -neg_fraction*log(neg_fraction+eps)\n",
    "    entropy = pos_entropy + neg_entropy\n",
    "    return entropy\n",
    "\n",
    "def find_entropy_attribute(df,key):\n",
    "    if(type(attributes.get(key))==list):\n",
    "        Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "        target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "        variables = df[key].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "        entropy2 = 0\n",
    "        threshold = None\n",
    "        threshold_dict[key] = threshold\n",
    "        for variable in variables:\n",
    "            entropy = 0\n",
    "            for target_variable in target_variables:\n",
    "                num = len(df[key][df[key]==variable][df[Class] == target_variable])\n",
    "                den = len(df[key][df[key]==variable])\n",
    "                fraction = num/(den+eps)\n",
    "                entropy += -fraction*log(fraction+eps)\n",
    "            fraction2 = den/len(df)\n",
    "            entropy2 += fraction2*entropy\n",
    "#             entropy2 += -fraction2*entropy\n",
    "    else:\n",
    "        threshold = 0\n",
    "        min_entropy = sys.maxsize\n",
    "        entropy2 = 0\n",
    "        threshold = None\n",
    "        zipped = list(zip(df[key], df[df.keys()[-1]]))\n",
    "        result = sorted(zipped, key = lambda x: x[0])\n",
    "#         print(result)\n",
    "        for i in range(len(result)):\n",
    "            entropy2 = 0\n",
    "            if(i!=0 and result[i][0]!=result[i-1][0]):      #check for all possible cases\n",
    "                mid_value = (float(result[i][0])+float(result[i-1][0]))/2.0\n",
    "#                 print(mid_value)\n",
    "                left_part = result[0:i]\n",
    "                left_part_count = len(left_part)\n",
    "                if(left_part_count == 0):\n",
    "                    continue\n",
    "#                 print(left_part)\n",
    "                entropy_left = entropy_continuous(df,left_part)\n",
    "                left_fraction = len(left_part)/len(df)\n",
    "                weighted_entropy_left = left_fraction*entropy_left\n",
    "                entropy2+= weighted_entropy_left\n",
    "#                 print(left_part_count)\n",
    "                right_part = result[i:]\n",
    "                right_part_count = len(right_part)\n",
    "                if(right_part_count != 0):\n",
    "                    entropy_right = entropy_continuous(df,right_part)\n",
    "                    right_fraction = len(right_part)/len(df)\n",
    "                    weighted_entropy_right = right_fraction*entropy_right\n",
    "                    entropy2+= weighted_entropy_right\n",
    "                    if(entropy2 < min_entropy):\n",
    "                        min_entropy = entropy2\n",
    "                        threshold = mid_value\n",
    "        entropy2 = min_entropy\n",
    "        threshold_dict[key] = threshold\n",
    "        #         print(right_part_count)\n",
    "                \n",
    "#             else:\n",
    "#                 print(\"Do nothing:\", i)\n",
    "    return (entropy2,threshold)\n",
    "#     return abs(entropy2)\n",
    "    \n",
    "\n",
    "def find_winner(df, attributes_copy):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in attributes_copy.keys():\n",
    "#         print(key)\n",
    "#         Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        entropy_attribute, threshold = find_entropy_attribute(df, key)\n",
    "#         print(entropy_attribute, threshold)\n",
    "        IG.append(find_entropy(df)-entropy_attribute)\n",
    "    return list(attributes_copy)[np.argmax(IG)], threshold_dict.get(list(attributes_copy)[np.argmax(IG)])\n",
    "\n",
    "# entropy_target = find_entropy(df)-find_entropy_attribute(df,'A6')\n",
    "# entropy_target\n",
    "# train_df.keys()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_entropy(df):\n",
    "#     Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "#     entropy = 0\n",
    "#     values = df[Class].unique()\n",
    "#     for value in values:\n",
    "#         fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "#         entropy += -fraction*np.log2(fraction)\n",
    "#     return entropy\n",
    "\n",
    "# def entropy_continuous(df,data_portion):\n",
    "#     data_portion_count = len(data_portion)\n",
    "# #     print(\"In entropy continuous:\" , data_portion_count)\n",
    "#     output = {}\n",
    "#     entropy = 0\n",
    "#     for x,y in data_portion:\n",
    "#         if y in output:\n",
    "#             output[y].append((x,y))\n",
    "#         else:\n",
    "#             output[y] = [(x,y)]\n",
    "# #     print(\"In entropy continuous:\", output)\n",
    "# #     print(\"In entropy continuous:\", len(output.get('+')))\n",
    "#     if ('+' in output.keys()):\n",
    "#         pos_labels_count = len(output.get('+'))\n",
    "#     else:\n",
    "#         pos_labels_count = 0\n",
    "#     neg_labels_count = data_portion_count - pos_labels_count\n",
    "#     pos_fraction = pos_labels_count/(data_portion_count+eps)\n",
    "#     pos_entropy = -pos_fraction*log(pos_fraction+eps)\n",
    "#     neg_fraction = neg_labels_count/(data_portion_count+eps)\n",
    "#     neg_entropy = -neg_fraction*log(neg_fraction+eps)\n",
    "#     entropy = pos_entropy + neg_entropy\n",
    "#     return entropy\n",
    "\n",
    "# def find_entropy_attribute(df,key):\n",
    "#     Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "#     target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "#     variables = df[key].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "#     entropy2 = 0\n",
    "#     threshold = None\n",
    "#     for variable in variables:\n",
    "#         entropy = 0\n",
    "#         for target_variable in target_variables:\n",
    "#             num = len(df[key][df[key]==variable][df[Class] == target_variable])\n",
    "#             den = len(df[key][df[key]==variable])\n",
    "#             fraction = num/(den+eps)\n",
    "#             entropy += -fraction*log(fraction+eps)\n",
    "#         fraction2 = den/len(df)\n",
    "#         entropy2 += fraction2*entropy\n",
    "#     return (entropy2,threshold)\n",
    "    \n",
    "\n",
    "# def find_winner(df, attributes_copy):\n",
    "#     Entropy_att = []\n",
    "#     IG = []\n",
    "#     for key in attributes_copy.keys():\n",
    "# #         print(key)\n",
    "# #         Entropy_att.append(find_entropy_attribute(df,key))\n",
    "#         entropy_attribute, threshold = find_entropy_attribute(df, key)\n",
    "#         IG.append(find_entropy(df)-entropy_attribute)\n",
    "#     return list(attributes_copy)[np.argmax(IG)], threshold\n",
    "\n",
    "# # entropy_target = find_entropy(df)-find_entropy_attribute(df,'A6')\n",
    "# # entropy_target\n",
    "# # attributes_copy.keys()\n",
    "# # list(attributes_copy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A9 None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (find_winner(train_df, attributes_copy)\n",
    "# threshold_dict\n",
    "entropy_attribute, threshold = find_winner(train_df, attributes_copy)\n",
    "print(entropy_attribute, threshold)\n",
    "len(attributes_copy)\n",
    "# print(\"Value\", threshold_dict.get('A9'))\n",
    "# type(attributes.get('A9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     490\n",
       "unique      2\n",
       "top         -\n",
       "freq      277\n",
       "Name: A16, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['A16'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_purity(data):\n",
    "    label_column = data.keys()[-1]\n",
    "    unique_classes = np.unique(data[label_column])\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(data):\n",
    "    \n",
    "    label_column = data.keys()[-1]\n",
    "    unique_classes, counts_unique_classes = np.unique(data[label_column], return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_class(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-45279881bc40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         df[key] = np.where(df[key] < threshold_dict.get(key), 0, df[key])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mconvert_continuous_to_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# df['A2'].values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# type(threshold_dict.get('A2'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# def convert_continuous_to_categorical(df,threshold_dict):\n",
    "#     for key in threshold_dict:\n",
    "#         print(\"Key value:\", key)\n",
    "#         df[key].astype(np.float)\n",
    "#         df.loc[df[key] > threshold_dict.get(key), key] = 1\n",
    "#         df.loc[df[key] <= threshold_dict.get(key), key] = 0\n",
    "# #         df[key] = np.where(df[key] >= threshold_dict.get(key), 1, df[key])\n",
    "# #         df[key] = np.where(df[key] < threshold_dict.get(key), 0, df[key])\n",
    "#         print(\"Done\")\n",
    "# convert_continuous_to_categorical(df,threshold_dict)\n",
    "# df['A2'].values\n",
    "# type(threshold_dict.get('A2'))\n",
    "# df['A14'] = df['A14'].astype(np.float)\n",
    "# type(df['A2'])\n",
    "# df['A14'].values\n",
    "# threshold_dict.values()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987658900015369"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy = find_entropy(train_df)\n",
    "# entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9638639717644055, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_entropy_attribute(train_df,'A4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "below (354, 16)\n",
      "above (136, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>45.83</td>\n",
       "      <td>10.5</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>36.67</td>\n",
       "      <td>4.415</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>10</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>47.75</td>\n",
       "      <td>8</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>7.875</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>bb</td>\n",
       "      <td>5.165</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>56.58</td>\n",
       "      <td>18.5</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>bb</td>\n",
       "      <td>15</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>17</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>b</td>\n",
       "      <td>51.83</td>\n",
       "      <td>2.04</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>1.5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>b</td>\n",
       "      <td>47.17</td>\n",
       "      <td>5.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>5.5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>465</td>\n",
       "      <td>150</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>a</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>a</td>\n",
       "      <td>41.58</td>\n",
       "      <td>1.04</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.665</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.29</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2     A3 A4 A5  A6  A7     A8 A9 A10 A11 A12 A13  A14   A15 A16\n",
       "0    a  45.83   10.5  u  g   q   v      5  t   t   7   t   g    0     0   +\n",
       "1    b  36.67  4.415  y  p   k   v   0.25  t   t  10   t   g  320     0   +\n",
       "2    a  47.75      8  u  g   c   v  7.875  t   t   6   t   g    0  1260   +\n",
       "3    a     47     13  u  g   i  bb  5.165  t   t   9   t   g    0     0   +\n",
       "4    b  56.58   18.5  u  g   d  bb     15  t   t  17   t   g    0     0   +\n",
       "..  ..    ...    ... .. ..  ..  ..    ... ..  ..  ..  ..  ..  ...   ...  ..\n",
       "131  b  51.83   2.04  y  p  ff  ff    1.5  f   f   0   f   g  120     1   -\n",
       "132  b  47.17  5.835  u  g   w   v    5.5  f   f   0   f   g  465   150   -\n",
       "133  a  50.25  0.835  u  g  aa   v    0.5  f   f   0   t   g  240   117   -\n",
       "134  a  41.58   1.04  u  g  aa   v  0.665  f   f   0   f   g  240   237   -\n",
       "135  b  40.58   3.29  u  g   m   v    3.5  f   f   0   t   s  400     0   -\n",
       "\n",
       "[136 rows x 16 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(df, split_column, split_value, type_of_feature):\n",
    "    data = df.values    \n",
    "    split_column_data = data[:,split_column]\n",
    "        \n",
    "\n",
    "#     type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"categorical\": \n",
    "        data_above_split = data[split_column_data != split_value]\n",
    "        data_below_split = data[split_column_data == split_value]\n",
    "        \n",
    "    # feature is continuous   \n",
    "    else:\n",
    "        print(\"yes\")\n",
    "        split_column_data =  split_column_data.astype(np.float)\n",
    "        data_above_split = data[split_column_data >  split_value]\n",
    "        data_below_split = data[split_column_data <= split_value]\n",
    "    \n",
    "    data_above_split = pd.DataFrame(data = data_above_split, columns = attributes.keys())\n",
    "    data_below_split = pd.DataFrame(data = data_below_split, columns = attributes.keys())\n",
    "    return data_above_split, data_below_split\n",
    "data_above_split, data_below_split = split_data(train_df,1,36.625,'continuous')\n",
    "print(\"below\", data_below_split.shape)\n",
    "print(\"above\", data_above_split.shape)\n",
    "type(data_above_split)\n",
    "data_above_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes.get('A1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, feature_types, attributes_copy, max_depth, min_samples=2, counter=0):\n",
    "    \n",
    "    # data preparations\n",
    "    data = df\n",
    "    if counter == 0:\n",
    "        global COLUMN_LABELS, FEATURE_TYPES\n",
    "        COLUMN_LABELS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "#         data = df.values\n",
    "#     else:\n",
    "#         data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_label_purity(df)) or (len(df) < min_samples) or (counter == max_depth) or len(attributes_copy)==0:\n",
    "        classification = majority_class(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "#         potential_splits = get_potential_splits(data)\n",
    "#         split_column, split_value = determine_best_split(data, potential_splits)\n",
    "#         data_above, data_below = split_data(data, split_column, split_value)\n",
    "        \n",
    "#         potential_splits = get_potential_splits(data)\n",
    "        node, threshold = find_winner(data, attributes_copy)\n",
    "        attributes_copy.pop(node)\n",
    "        type_of_feature = feature_types[int(node[1:])]\n",
    "        data_above, data_below = split_data(data, int(node[1:])-1, threshold, type_of_feature)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0:\n",
    "            classification = majority_class(data)\n",
    "            return classification\n",
    "        \n",
    "        if len(data_above) == 0:\n",
    "            classification = majority_class(data)\n",
    "            return classification\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = node\n",
    "#        use this for type of feature = feature_types[int(find_winner(train_df)[0][1:])]\n",
    "#         type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"categorical\":\n",
    "            values = attributes.get(feature_name)\n",
    "            for split_value in values:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "                sub_tree = {question: []}\n",
    "            \n",
    "        # feature is continuous\n",
    "        else:\n",
    "            question = \"{} <= {}\".format(feature_name, threshold)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, feature_types, attributes_copy, max_depth,  min_samples, counter)\n",
    "        no_answer = decision_tree_algorithm(data_above, feature_types, attributes_copy, max_depth, min_samples, counter)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9867798849009974 None\n",
      "0.9500014251209004 36.625\n",
      "0.9509894205998639 4.1875\n",
      "0.9638639717644055 None\n",
      "0.9638639717644055 None\n",
      "0.9167768268934827 None\n",
      "0.9845959106798634 None\n",
      "0.9799538529493227 None\n",
      "0.9633334834134044 356.0\n",
      "yes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-e4f2fedf1562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-3df46cd9439c>\u001b[0m in \u001b[0;36mdecision_tree_algorithm\u001b[1;34m(df, feature_types, attributes_copy, max_depth, min_samples, counter)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mattributes_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtype_of_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mdata_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_below\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_of_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# check for empty data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-72ca72572fbc>\u001b[0m in \u001b[0;36msplit_data\u001b[1;34m(df, split_column, split_value, type_of_feature)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msplit_column_data\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msplit_column_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mdata_above_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit_column_data\u001b[0m \u001b[1;33m>\u001b[0m  \u001b[0msplit_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdata_below_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit_column_data\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0msplit_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'v'"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df, feature_types, attributes_copy, max_depth=20)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.val = []\n",
    "        self.children = {}\n",
    "        self.target_val = -1\n",
    "\n",
    "    def add_child(self, cat, node):\n",
    "        self.children[cat] = node\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.val) + \" \" + str(self.target_val)\n",
    "\n",
    "\n",
    "def printTree(node, key, parent):\n",
    "    print(parent, key, node)\n",
    "\n",
    "    for key, child in node.children.items():\n",
    "        printTree(child, key, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.710</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>36.67</td>\n",
       "      <td>4.415</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>10</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>23.25</td>\n",
       "      <td>1.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>0.835</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.750</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>b</td>\n",
       "      <td>35</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2      A3 A4 A5  A6 A7     A8 A9 A10  A11 A12 A13  A14  A15 A16\n",
       "0    b  30.83   0.000  u  g   w  v  1.250  t   t    1   f   g  202    0   +\n",
       "2    b  20.17   5.625  u  g   w  v  1.710  t   f    0   f   s  120    0   +\n",
       "3    b  32.08   4.000  u  g   m  v  2.500  t   f    0   t   g  360    0   +\n",
       "5    b  36.67   4.415  y  p   k  v  0.250  t   t   10   t   g  320    0   +\n",
       "7    b  23.25   1.000  u  g   c  v  0.835  t   f    0   f   s  300    0   +\n",
       "..  ..    ...     ... .. ..  .. ..    ... ..  ..  ...  ..  ..  ...  ...  ..\n",
       "483  b  36.42   0.750  y  p   d  v  0.585  f   f    0   f   g  240    3   -\n",
       "484  b  40.58   3.290  u  g   m  v  3.500  f   f    0   t   s  400    0   -\n",
       "485  b  21.08  10.085  y  p   e  h  1.250  f   f    0   f   g  260    0   -\n",
       "488  b  17.92   0.205  u  g  aa  v  0.040  f   f    0   f   g  280  750   -\n",
       "489  b     35   3.375  u  g   c  h  8.290  f   f    0   t   g    0    0   -\n",
       "\n",
       "[338 rows x 16 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attr = 'A4'\n",
    "# feature_types[int(attr[1:]) - 1]\n",
    "# train_df[train_df['A1'] == 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df, attribute_features, depth, maxDepth, feature_types):\n",
    "    node = Node()\n",
    "    \n",
    "    target = len(df.columns)-1\n",
    "    if depth == maxDepth or (len(attribute_features) == 0) or (len(df) <= 1) or check_label_purity(df) :\n",
    "        tmp = df.iloc[:,target].mode()\n",
    "#         classification = majority_class(df)\n",
    "        if (len(tmp) == 0):\n",
    "            node.target_val = 0\n",
    "        else:\n",
    "            node.target_val = tmp.iloc[0]\n",
    "#         node.target_val = classification\n",
    "        return node\n",
    "\n",
    "    attr, thresh = find_winner(df, attribute_features)\n",
    "#     print(attr)\n",
    "    type_of_feature = feature_types[int(attr[1:]) - 1]\n",
    "#     # categorial attribute\n",
    "#     if thresh == 'None':\n",
    "#         thresh = attributes.get(attr)\n",
    "\n",
    "    \n",
    "#     at_orig = [x for x in attributes if x != attr]\n",
    "    attribute_features.pop(attr)\n",
    "    # at_orig.remove(attr)\n",
    "\n",
    "    if type_of_feature == 'categorical':\n",
    "        thresh = attributes.get(attr)\n",
    "        node.val = [attr, thresh]\n",
    "        for val in thresh:\n",
    "            node.add_child(val, build_tree(df[df[attr] == val], attribute_features, depth+1, maxDepth, feature_types))\n",
    "    else:\n",
    "        node.val = [attr, thresh]\n",
    "        node.add_child('leq', build_tree(df[df[attr] <= thresh], attribute_features, depth+1, maxDepth, feature_types))\n",
    "        node.add_child('ge', build_tree(df[df[attr] > thresh], attribute_features, depth+1, maxDepth, feature_types))\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none root ['A9', ['t', 'f']] -1\n",
      "['A9', ['t', 'f']] -1 t ['A15', 385.5] -1\n",
      "['A15', 385.5] -1 leq ['A8', 1.395] -1\n",
      "['A8', 1.395] -1 leq ['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 c ['A14', 220.0] -1\n",
      "['A14', 220.0] -1 leq [] -\n",
      "['A14', 220.0] -1 ge [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 d [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 cc [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 i ['A2', 28.125] -1\n",
      "['A2', 28.125] -1 leq ['A3', 6.9175] -1\n",
      "['A3', 6.9175] -1 leq [] +\n",
      "['A3', 6.9175] -1 ge [] -\n",
      "['A2', 28.125] -1 ge [] -\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 j [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 k ['A11', 6.5] -1\n",
      "['A11', 6.5] -1 leq [] -\n",
      "['A11', 6.5] -1 ge [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 m ['A12', ['t', 'f']] -1\n",
      "['A12', ['t', 'f']] -1 t [] +\n",
      "['A12', ['t', 'f']] -1 f [] -\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 r [] 0\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 q ['A1', ['b', 'a']] -1\n",
      "['A1', ['b', 'a']] -1 b [] +\n",
      "['A1', ['b', 'a']] -1 a ['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 v ['A4', ['u', 'y', 'l', 't']] -1\n",
      "['A4', ['u', 'y', 'l', 't']] -1 u ['A5', ['g', 'p', 'gg']] -1\n",
      "['A5', ['g', 'p', 'gg']] -1 g ['A10', ['t', 'f']] -1\n",
      "['A10', ['t', 'f']] -1 t ['A13', ['g', 'p', 's']] -1\n",
      "['A13', ['g', 'p', 's']] -1 g [] +\n",
      "['A13', ['g', 'p', 's']] -1 p [] 0\n",
      "['A13', ['g', 'p', 's']] -1 s [] 0\n",
      "['A10', ['t', 'f']] -1 f [] 0\n",
      "['A5', ['g', 'p', 'gg']] -1 p [] 0\n",
      "['A5', ['g', 'p', 'gg']] -1 gg [] 0\n",
      "['A4', ['u', 'y', 'l', 't']] -1 y [] 0\n",
      "['A4', ['u', 'y', 'l', 't']] -1 l [] 0\n",
      "['A4', ['u', 'y', 'l', 't']] -1 t [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 h [] +\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 bb [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 j [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 n [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 z [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 dd [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 ff [] 0\n",
      "['A7', ['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o']] -1 o [] 0\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 w [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 x [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 e [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 aa [] +\n",
      "['A6', ['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff']] -1 ff [] +\n",
      "['A8', 1.395] -1 ge [] +\n",
      "['A15', 385.5] -1 ge [] +\n",
      "['A9', ['t', 'f']] -1 f [] -\n"
     ]
    }
   ],
   "source": [
    "attributes_copy = attributes.copy()\n",
    "attributes_copy.pop('A16')\n",
    "node = build_tree(train_df,attributes_copy,0,20,feature_types)\n",
    "printTree(node,\"root\",\"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(df, root):\n",
    "    labels = []\n",
    "    # tar = len(df.columns) - 1\n",
    "    node = root\n",
    "    # acc = 0\n",
    "    for _, row in df.iterrows():\n",
    "        while node.target_val == -1:\n",
    "            b_attr = node.val[0]\n",
    "            b_val = node.val[1]\n",
    "            if isinstance(b_val, list):\n",
    "                t_val = row[b_attr]\n",
    "                node = node.children[t_val]\n",
    "            else :\n",
    "                t_val = row[b_attr]\n",
    "                if (t_val <= b_val):\n",
    "                    node = node.children['leq']\n",
    "                else :\n",
    "                    node = node.children['ge']\n",
    "        # print(row[tar], node.target_val)\n",
    "        # if(row[tar] == node.target_val):\n",
    "        # \tacc += 1\n",
    "        labels.append(node.target_val)\n",
    "        node = root\n",
    "    # print(acc/len(df))\n",
    "    return labels\n",
    "predicted_labels = evaluate(train_df,node)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Accuracy: 0.9510204081632653\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "def accuracy(orig, pred):\n",
    "    num = len(pred)\n",
    "    if(num != len(pred)):\n",
    "        print('Error!! Num of labels are not equal.')\n",
    "        return\n",
    "    match = 0\n",
    "    for i in range(len(orig)):\n",
    "        o_label = orig[i]\n",
    "        p_label = pred[i]\n",
    "        if(o_label == p_label):\n",
    "            match += 1\n",
    "    print('***************\\nAccuracy: ' + str(float(match)/num) + '\\n***************')\n",
    "original_labels = train_df['A16'].values\n",
    "accuracy_score = accuracy(original_labels, predicted_labels)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Accuracy: 0.5373134328358209\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "test_df= pd.read_csv(\"test.txt\",sep = '\\t', header = None, names = attributes.keys())\n",
    "test_df\n",
    "fill_missing_values(test_df)\n",
    "test_prediction_label = evaluate(test_df,node)\n",
    "test_original_label = test_df['A16'].values\n",
    "test_accuracy_score = accuracy(test_original_label, test_prediction_label)\n",
    "test_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11',\n",
       "       'A12', 'A13', 'A14', 'A15', 'A16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,features,target_attribute_name=\"A16\",parent_node_class = None):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm: This function takes five paramters:\n",
    "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
    " \n",
    "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
    "    in the case the dataset delivered by the first parameter is empty\n",
    "\n",
    "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
    "    we have to remove features from our dataset --> Splitting at each node\n",
    "\n",
    "    4. target_attribute_name = the name of the target attribute\n",
    "\n",
    "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is \n",
    "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
    "    space, we want to return the mode target feature value of the direct parent node.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "\n",
    "#     # base cases\n",
    "#     if (check_label_purity(df)) or (len(df) < min_samples) or (counter == max_depth):\n",
    "#         classification = majority_class(data)\n",
    "#         return classification\n",
    "#     print(\"PNC\", parent_node_class)\n",
    "#     print(\"Attribute Feature len\", len(features))\n",
    "    classification = majority_class(data)\n",
    "#     If all target_values have the same value, return this value\n",
    "    if check_label_purity(data):\n",
    "        print(\"Yes\")\n",
    "#         classification = majority_class(data)\n",
    "        return classification\n",
    "#     if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "#         return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        print(\"Yes1\")\n",
    "#         classification = majority_class(data)\n",
    "        return classification\n",
    "#         return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
    "    #the mode target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) == 0:\n",
    "        print(\"Yes2\")\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mode target feature value of the current node\n",
    "#         parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        parent_node_class = classification\n",
    "#         print(\"PNC inside\", parent_node_class)\n",
    "        #Select the feature which best splits the dataset\n",
    "#         item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "#         best_feature_index = np.argmax(item_values)\n",
    "#         best_feature = features[best_feature_index]\n",
    "        \n",
    "#         item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature, split_value = find_winner(data, features)\n",
    "#         best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
    "        #gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "#         features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        features.pop(best_feature)\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = data[data[best_feature] == value]\n",
    "            \n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = ID3(sub_data,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes2\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes2\n",
      "Yes2\n",
      "Yes2\n",
      "Yes2\n",
      "Yes2\n",
      "Yes\n",
      "Yes2\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes2\n",
      "Yes\n",
      "Yes\n",
      "Yes2\n",
      "Yes2\n",
      "{'A9': {'f': {'A6': {'aa': '-',\n",
      "                     'c': {'A13': {'g': {'A12': {'f': {'A4': {'u': {'A1': {'a': '-',\n",
      "                                                                           'b': {'A10': {'f': {'A7': {'h': '-',\n",
      "                                                                                                      'v': {'A2': {'Val >=15.83': {'A3': {'Val >=0.0': {'A5': {'g': {'A8': {'Val >=0.0': {'A11': {'Val >=0.0': {'A14': {'Val >=0.0': {'A15': {'Val >=0.0': '-'}}}}}}}}}}}}}}}},\n",
      "                                                                                         't': '-'}}}},\n",
      "                                                              'y': '-'}},\n",
      "                                                 't': '-'}},\n",
      "                                   'p': '-',\n",
      "                                   's': '-'}},\n",
      "                     'cc': '-',\n",
      "                     'd': '-',\n",
      "                     'e': '-',\n",
      "                     'ff': '-',\n",
      "                     'i': '-',\n",
      "                     'j': '-',\n",
      "                     'k': '-',\n",
      "                     'm': '-',\n",
      "                     'q': '-',\n",
      "                     'r': '-',\n",
      "                     'w': '-',\n",
      "                     'x': '-'}},\n",
      "        't': '-'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "attributes_copy = attributes.copy()\n",
    "attributes_copy.pop('A16')\n",
    "# tree = buildTree(transformed_data)\n",
    "ID3_tree = ID3(transformed_data,attributes_copy)\n",
    "pprint.pprint(ID3_tree)\n",
    "# len(attributes_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    #This function is used to predict for any input variable \n",
    "    \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "\n",
    "    for nodes in tree.keys():        \n",
    "        \n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = 0\n",
    "            \n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;                            \n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ['-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '-' '-' '-' '-']\n"
     ]
    }
   ],
   "source": [
    "def get_predicted_labels(df):\n",
    "    predict_labels = []\n",
    "    for i in range(len(df.index)):\n",
    "        inst = df.iloc[i]\n",
    "        prediction = predict(inst, ID3_tree)\n",
    "        predict_labels.append(prediction)\n",
    "    original_labels = df['A16'].values\n",
    "    predict_labels = np.array(predict_labels)\n",
    "    return predict_labels, original_labels\n",
    "predict_labels, original_labels = get_predicted_labels(transformed_data)\n",
    "print(\"Predicted\", predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(orig, pred):\n",
    "    num = len(pred)\n",
    "    if(num != len(pred)):\n",
    "        print('Error!! Num of labels are not equal.')\n",
    "        return\n",
    "    match = 0\n",
    "    for i in range(len(orig)):\n",
    "        o_label = orig[i]\n",
    "        p_label = pred[i]\n",
    "        if(o_label == p_label):\n",
    "            match += 1\n",
    "    print('***************\\nAccuracy: ' + str(float(match)/num) + '\\n***************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>h</td>\n",
       "      <td>6.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>164</td>\n",
       "      <td>31285</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>22.92</td>\n",
       "      <td>11.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>80</td>\n",
       "      <td>1349</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>h</td>\n",
       "      <td>3.960</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>180</td>\n",
       "      <td>314</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>42.5</td>\n",
       "      <td>4.915</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.165</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>52</td>\n",
       "      <td>1442</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0.830</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>2.165</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>b</td>\n",
       "      <td>32.33</td>\n",
       "      <td>3.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>b</td>\n",
       "      <td>?</td>\n",
       "      <td>0.040</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>4.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>b</td>\n",
       "      <td>47.83</td>\n",
       "      <td>4.165</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>x</td>\n",
       "      <td>bb</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>1.250</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.125</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>b</td>\n",
       "      <td>27.58</td>\n",
       "      <td>3.250</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>5.085</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2      A3 A4 A5  A6  A7     A8 A9 A10  A11 A12 A13  A14    A15 A16\n",
       "0    b  33.17   1.040  u  g   r   h  6.500  t   f    0   t   g  164  31285   +\n",
       "1    a  22.92  11.585  u  g  cc   v  0.040  t   f    0   f   g   80   1349   +\n",
       "2    b  54.42   0.500  y  p   k   h  3.960  t   f    0   f   g  180    314   +\n",
       "3    b   42.5   4.915  y  p   w   v  3.165  t   f    0   t   g   52   1442   +\n",
       "4    b  22.08   0.830  u  g   c   h  2.165  f   f    0   t   g  128      0   +\n",
       "..  ..    ...     ... .. ..  ..  ..    ... ..  ..  ...  ..  ..  ...    ...  ..\n",
       "129  b  32.33   3.500  u  g   k   v  0.500  f   f    0   t   g  232      0   -\n",
       "130  b      ?   0.040  y  p   d   v  4.250  f   f    0   t   g  460      0   -\n",
       "131  b  47.83   4.165  u  g   x  bb  0.085  f   f    0   t   g  520      0   -\n",
       "132  b     20   1.250  y  p   k   v  0.125  f   f    0   f   g  140      4   -\n",
       "133  b  27.58   3.250  y  p   q   h  5.085  f   t    2   t   g  369      1   -\n",
       "\n",
       "[134 rows x 16 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df= pd.read_csv(\"test.txt\",sep = '\\t', header = None, names = attributes.keys())\n",
    "test_df\n",
    "# if '?' in test_df.values:\n",
    "#     print('Element ? exists in Dataframe')\n",
    "# else:\n",
    "#     print('Element ? does not exists in Dataframe')\n",
    "# test_df_copy = fill_missing_values(test_df)\n",
    "# if '?' in test_df_copy.values:\n",
    "#     print('Element ? exists in Dataframe')\n",
    "# else:\n",
    "#     print('Element ? does not exists in Dataframe')\n",
    "# test_df\n",
    "# if '?' in test_df.values:\n",
    "#     print('Element ? exists in Dataframe')\n",
    "# else:\n",
    "#     print('Element ? does not exists in Dataframe')\n",
    "# transformed_test_data = continuous_to_categorical_data(test_df)\n",
    "# transformed_test_data\n",
    "# orig,pred = get_predicted_labels(df_test)\n",
    "# print(len(orig), len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Accuracy: 0.5653061224489796\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = accuracy(original_labels, predict_labels)\n",
    "accuracy_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
